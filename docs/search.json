[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "",
    "section": "",
    "text": "Andrew M. Demetriou\n Email\n LinkedIn\n Scholar\n GitHub\n ORCID\n\n\n\nI work on Trustworthy AI.\nI aim to bring more thought to how we measure the performance of AI systems, by bringing knowledge from the social sciences into  ground-truthing  - the process of designing, gathering, and evaluating the data we use to measure the performance of AI systems.\n\nView My Projects"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "",
    "section": "",
    "text": "Andrew M. Demetriou\n Email\n LinkedIn\n Scholar\n GitHub\n ORCID\n\n\n\nShaping AI with Measurement\nI think of AI system evaluations as measurements. The more precise the measurement, the better we can align AI systems it.I think of the data that we use to evaluate AI systems - often called the ‚Äúgold standard‚Äù or the ‚Äúground truth‚Äù - as a measurement problem, and pursuit of useful ways to measure AI systems as a key challenge. I try to bring in knowledge from my experience of the way other fields measure - VR-based field studies, hormones from hair and saliva samples, psychometric questionnaires, electro-cardiac measures using the VU-DAMS, in Psychology in Criminology, in academia and industry - to improve how we evaluate AI.\nMy PhD thesis aimed to understand how to design, collect, and analyze ground truth, in challenging situations where there is no single truth, but rather multiple perspectives. It also informs generally how to ‚Äúground‚Äù psychological phenomena in text. The case study of my thesis involved measuring the basic values in song lyrics and political speeches. I brought knowledge from the Social Sciences, particularly psychometrics, to inform how to go about the process of ‚Äúgrounding‚Äù as a Trustworthy Artificial Intelligence (AI) systems PhD candidate in the Intelligent Systems department at Delft University of Technology, in the lab of Cynthia C. S. Liem.\nI‚Äôm now looking to build on my experiences in a way that benefits as many people as possible.\n\n\n\nEducation\n PhD in Computer Science,\n(ABD) Delft University of Technology\n Research MSc in Psychology,\nVrije Universiteit Amsterdam, Cum Laude\n BA in Philosphy and Political Science, CUNY Queens College"
  },
  {
    "objectID": "about.html#about",
    "href": "about.html#about",
    "title": "Andrew M. Demetriou",
    "section": "",
    "text": "Andrew M. Demetriou is researching Trustworthy Artificial Intelligence (AI) systems as a PhD candidate in the Intelligent Systems department at Delft University of Technology. He works as part of a lab aimed at increasing the trustworthiness of AI technology, focusing on how to gather and evaluate the quality of data used as Ground Truth in AI systems. Specifically, he applies knowledge from the fields of Psychometrics and Survey Science to develop reproducible data gathering and evaluation procedures from participants.\n\n\n\n\n\nResponsible AI Systems\n\nGround Truthing for AI\n\nAI for Social Science\n\nOpen Science\n\n\n\n\n\n\n PhD in Artificial Intelligence,\n(ABD) Delft University of Technology\n Research MSc in Psychology,\nVrije Universiteit Amsterdam, Cum Laude"
  },
  {
    "objectID": "licenses.html",
    "href": "licenses.html",
    "title": "",
    "section": "",
    "text": "üìú Licensing: This repository is dual-licensed to support both code reuse and responsible content sharing:\nüíª Code: Repositories with code (e.g.¬†R scripts, Quarto setup) is licensed under the MIT License. ‚Üí You are free to use, modify, and distribute the code, as long as attribution is given.\nüìÑ Written content: Text and other descriptions (e.g.¬†project write-ups) are licensed under the Creative Commons Attribution 4.0 International License (CC BY 4.0). ‚Üí This allows sharing and adaptation, with attribution.\nIf you‚Äôre unsure how to reuse any part of this project or you‚Äôd like to collaborate, feel free to open an issue or contact me by email."
  },
  {
    "objectID": "projects.html",
    "href": "projects.html",
    "title": "",
    "section": "",
    "text": "Most widely consumed music in Western countries includes song lyrics, with US samples indicating that nearly all personal song libraries contain lyrics. Social science theory suggests that personal values expressed in widely consumed text, like song lyrics, may align with or diverge from those of the listener, potentially shaping their response to the music. This highlights the potential of automated value estimation in lyrics for downstream music information retrieval (MIR) tasks, like personalization. Like prior work, we adopt a perspectivist approach informed by social science theory to reliably collect annotations and assess their quality. We then use a novel approach to automatically estimate values in song lyrics using large language models (LLMs), combined with programmatic prompt optimizer DSPy, gathering multiple estimates from each LLM to estimate intra-model reliability. We then compare aggregated human ratings with aggregated ratings from a subset of the most reliable LLMs, showing promising initial results. At the same time, in response to concerns about the energy footprint of LLMs, we monitor energy usage. We conclude that the results are a positive step forward in terms of estimating values in lyrics, but open challenges remain on the side of reliability and power requirements."
  },
  {
    "objectID": "projects.html#towards-estimating-values-from-lyrics-cultural-meaning-at-scale",
    "href": "projects.html#towards-estimating-values-from-lyrics-cultural-meaning-at-scale",
    "title": "Projects",
    "section": "",
    "text": "View on GitHub\n\n\n\n\nThis project investigates how cultural values manifest in popular music lyrics, using a hybrid of computational social science, word embeddings, and music information retrieval. We developed a novel method to estimate value orientations (e.g., self-direction vs.¬†conformity) from song lyrics across time, genres, and regions.\n\nüìä Built reproducible evaluation pipelines in R and Python\n\nüéØ Designed proxy tasks to validate model alignment with human value ratings\n\nüß† Co-authored the conceptual framework + led data wrangling and visualization\n\nüìç Submission under review at ISMIR 2025"
  },
  {
    "objectID": "projects.html#towards-estimating-values-from-lyrics",
    "href": "projects.html#towards-estimating-values-from-lyrics",
    "title": "",
    "section": "",
    "text": "Most widely consumed music in Western countries includes song lyrics, with US samples indicating that nearly all personal song libraries contain lyrics. Social science theory suggests that personal values expressed in widely consumed text, like song lyrics, may align with or diverge from those of the listener, potentially shaping their response to the music. This highlights the potential of automated value estimation in lyrics for downstream music information retrieval (MIR) tasks, like personalization. Like prior work, we adopt a perspectivist approach informed by social science theory to reliably collect annotations and assess their quality. We then use a novel approach to automatically estimate values in song lyrics using large language models (LLMs), combined with programmatic prompt optimizer DSPy, gathering multiple estimates from each LLM to estimate intra-model reliability. We then compare aggregated human ratings with aggregated ratings from a subset of the most reliable LLMs, showing promising initial results. At the same time, in response to concerns about the energy footprint of LLMs, we monitor energy usage. We conclude that the results are a positive step forward in terms of estimating values in lyrics, but open challenges remain on the side of reliability and power requirements."
  },
  {
    "objectID": "projects.html#towards-estimating-values-from-lyrics-1",
    "href": "projects.html#towards-estimating-values-from-lyrics-1",
    "title": "Projects",
    "section": "",
    "text": "Most widely consumed music in Western countries includes song lyrics, with US samples indicating that nearly all personal song libraries contain lyrics. Social science theory suggests that personal values expressed in widely consumed text, like song lyrics, may align with or diverge from those of the listener, potentially shaping their response to the music. This highlights the potential of automated value estimation in lyrics for downstream music information retrieval (MIR) tasks, like personalization. Like prior work, we adopt a perspectivist approach informed by social science theory to reliably collect annotations and assess their quality. We then use a novel approach to automatically estimate values in song lyrics using large language models (LLMs), combined with programmatic prompt optimizer DSPy, gathering multiple estimates from each LLM to estimate intra-model reliability. We then compare aggregated human ratings with aggregated ratings from a subset of the most reliable LLMs, showing promising initial results. At the same time, in response to concerns about the energy footprint of LLMs, we monitor energy usage. We conclude that the results are a positive step forward in terms of estimating values in lyrics, but open challenges remain on the side of reliability and power requirements."
  },
  {
    "objectID": "projects.html#position-stop-making-unscientific-agi-performance-claims",
    "href": "projects.html#position-stop-making-unscientific-agi-performance-claims",
    "title": "",
    "section": "Position: Stop Making Unscientific AGI Performance Claims",
    "text": "Position: Stop Making Unscientific AGI Performance Claims\n\nICML‚Äô24\nDevelopments in the field of Artificial Intelligence (AI), and particularly large language models (LLMs), have created a ‚Äòperfect storm‚Äô for observing ‚Äòsparks‚Äô of Artificial General Intelligence (AGI) that are spurious. Like simpler models, LLMs distill meaningful representations in their latent embeddings that have been shown to correlate with external variables. Nonetheless, the correlation of such representations has often been linked to human-like intelligence in the latter but not the former. We probe models of varying complexity including random projections, matrix decompositions, deep autoencoders and transformers: all of them successfully distill information that can be used to predict latent or external variables and yet none of them have previously been linked to AGI. We argue and empirically demonstrate that the finding of meaningful patterns in latent spaces of models cannot be seen as evidence in favor of AGI. Additionally, we review literature from the social sciences that shows that humans are prone to seek such patterns and anthropomorphize. We conclude that both the methodological setup and common public image of AI are ideal for the misinterpretation that correlations between model representations and some variables of interest are ‚Äòcaused‚Äô by the model‚Äôs understanding of underlying ‚Äòground truth‚Äô relationships. We, therefore, call for the academic community to exercise extra caution, and to be keenly aware of principles of academic integrity, in interpreting and communicating about AI research outcomes."
  },
  {
    "objectID": "index.html#i-work-on-trustworthy-ai.",
    "href": "index.html#i-work-on-trustworthy-ai.",
    "title": "",
    "section": "",
    "text": "I aim to bring more thought to how we measure the performance of AI systems, by bringing knowledge from the social sciences into ‚Äòground-truthing‚Äô - the process of designing, gathering, and evaluating the data we use to measure the performance of AI systems.\n\nView My Projects"
  },
  {
    "objectID": "index.html#i-aim-to-bring-more-thought-to-how-we-measure-the-performance-of-ai-systems-by-bringing-knowledge-from-the-social-sciences-into-ground-truthing---the-process-of-designing-gathering-and-evaluating-the-data-we-use-to-measure-the-performance-of-ai-systems.",
    "href": "index.html#i-aim-to-bring-more-thought-to-how-we-measure-the-performance-of-ai-systems-by-bringing-knowledge-from-the-social-sciences-into-ground-truthing---the-process-of-designing-gathering-and-evaluating-the-data-we-use-to-measure-the-performance-of-ai-systems.",
    "title": "",
    "section": "",
    "text": "View My Projects"
  },
  {
    "objectID": "about.html#shaping-ai-with-measurement",
    "href": "about.html#shaping-ai-with-measurement",
    "title": "",
    "section": "",
    "text": "I think of AI system evaluations as measurements. The more precise the measurement, the better we can align AI systems it. I had an interest in measurement for some time, and have had the opportunity to work on a range of projects: VR-based field studies, hormones from hair and saliva samples, psychometric questionnaires, electro-cardiac measures using the VU-DAMS, in Psychology in Criminology, in academia and industry. I think of the data that we use to evaluate AI systems - often called the ‚Äúgold standard‚Äù or the ‚Äúground truth‚Äù - as a measurement problem, and pursuit of useful ways to measure AI systems as a key challenge. I try to bring in knowledge from the way other fields measure, to improve AI system evaluations.\nMy thesis aimed to understand how to design, collect, and analyze ground truth, in challenging situations where there is no single truth, but rather multiple perspectives. It also informs generally how to ‚Äúground‚Äù psychological phenomena in text. The case study of my thesis involved measuring the basic values in song lyrics and political speeches. I brought knowledge from the Social Sciences, particularly psychometrics, to inform how to go about the process of ‚Äúgrounding‚Äù as a Trustworthy Artificial Intelligence (AI) systems PhD candidate in the Intelligent Systems department at Delft University of Technology, in the lab of Cynthia C. S. Liem.\n\n\n\n PhD in Computer Science,\n(ABD) Delft University of Technology\n Research MSc in Psychology,\nVrije Universiteit Amsterdam, Cum Laude\n BA in Philosphy and Political Science, CUNY Queens College"
  }
]